[
{
	"uri": "//localhost:1313/vi/3-build-model/3.1-basic-sentiment-model/",
	"title": "Mô hình cảm xúc đơn giản",
	"tags": [],
	"description": "",
	"content": "Mô hình cảm xúc (sentiment model) là một loại mô hình học máy có thể phân tích một đoạn văn bản và xác định cảm xúc đằng sau nó—liệu nó là tích cực, tiêu cực, hay trung tính. Những mô hình này thường được sử dụng trong các lĩnh vực như: Phân tích phản hồi khách hàng, Giám sát mạng xã hội, Phân loại đánh giá sản phẩm,\u0026hellip;\nTrong phần này, chúng ta sẽ đi qua cách thu thập dữ liệu, tiền xử lý văn bản, huấn luyện mô hình học máy, và đưa ra dự đoán bằng Python. Cuối phiên này, bạn sẽ có một công cụ phân tích cảm xúc hoạt động mà bạn có thể thử nghiệm hoặc thậm chí cải thiện thêm.\nHãy bắt đầu Tạo môi trường để phát triển mô hình Tạo môi trường ảo python Tạo một thư mục mới và mở nó bằng VS Code rồi gõ python -m venv \u0026lt;tên của môi trường ảo\u0026gt; trong terminal. Tạo file create_sentiment_model.py Thu thập dữ liệu Trong workshop này, thay vì thu thập dữ liệu thô thủ công, chúng ta sẽ sử dụng một bộ dữ liệu có sẵn để phân tích cảm xúc. Trong hướng dẫn này, chúng ta sẽ sử dụng bộ dữ liệu đánh giá phim IMDb và dữ liệu đánh giá Yelp. Đầu tiên, chúng ta sẽ kích hoạt môi trường ảo đã tạo trước đó, gõ \u0026lt;tên của venv\u0026gt;/Scripts/activate. Tiếp theo, cài đặt thư viện dataset để sử dụng bộ dữ liệu có sẵn. pip install datasets Bây giờ, hãy xem có gì bên trong những bộ dữ liệu này. (Bạn không cần phải làm theo bước này. Bước này chỉ nhằm mục đích để bạn có cái nhìn cụ thể về thư viện này) Bắt đầu xây dựng Chuẩn bị dữ liệu huấn luyện và dữ liệu kiểm tra (Vì dữ liệu trong mỗi bộ dữ liệu khá nhỏ nên tác giả quyết định kết hợp chúng lại với nhau. Nếu dữ liệu chuẩn bị của bạn đủ lớn, bạn không cần phải làm như vậy) Tiền xử lý dữ liệu\nCài đặt thư viện scikit-learn để tạo mô hình pip install scikit-learn Mục đích của bước này: Chuyển đổi dữ liệu văn bản thành định dạng số bằng TF-IDF (Term Frequency - Inverse Document Frequency) để mô hình học máy có thể hiểu và xử lý đầu vào. Bước này giúp biểu diễn mỗi tài liệu dưới dạng vector dựa trên tầm quan trọng của từ, làm cho nó phù hợp cho việc huấn luyện và dự đoán.\nTạo mô hình Đánh giá mô hình Lưu mô hình và vectorizer Mã nguồn:\nfrom datasets import load_dataset\r# Load the datasets imdb_dataset = load_dataset(\u0026#34;imdb\u0026#34;)\ryelp_dataset = load_dataset(\u0026#34;yelp_polarity\u0026#34;)\r# Trích xuất dữ liệu train IMDB\rX_imdb_train = imdb_dataset[\u0026#39;train\u0026#39;][\u0026#39;text\u0026#39;][:]\ry_imdb_train = imdb_dataset[\u0026#39;train\u0026#39;][\u0026#39;label\u0026#39;][:]\r# Trích xuất dữ liệu train Yelp\rX_yelp_train = yelp_dataset[\u0026#39;train\u0026#39;][\u0026#39;text\u0026#39;][:]\ry_yelp_train = yelp_dataset[\u0026#39;train\u0026#39;][\u0026#39;label\u0026#39;][:]\r# Combine train datasets\rX_train = X_imdb_train + X_yelp_train\ry_train = y_imdb_train + y_yelp_train\r# Trích xuất dữ liệu test IMDB\rX_imdb_test = imdb_dataset[\u0026#39;test\u0026#39;][\u0026#39;text\u0026#39;][:]\ry_imdb_test = imdb_dataset[\u0026#39;test\u0026#39;][\u0026#39;label\u0026#39;][:]\r# Trích xuất dữ liệu test Yelp\rX_yelp_test = yelp_dataset[\u0026#39;test\u0026#39;][\u0026#39;text\u0026#39;][:]\ry_yelp_test = yelp_dataset[\u0026#39;test\u0026#39;][\u0026#39;label\u0026#39;][:]\r# Combine test datasets\rX_test = X_imdb_test + X_yelp_test\ry_test = y_imdb_test + y_yelp_test\r# Tiền xử lý dữ liệu\rfrom sklearn.feature_extraction.text import TfidfVectorizer\rvectorizer = TfidfVectorizer()\rX_train_tfidf = vectorizer.fit_transform(X_train)\rX_test_tfidf = vectorizer.transform(X_test)\r# Tạo mô hình\rfrom sklearn.linear_model import LogisticRegression\rmodel = LogisticRegression()\rmodel.fit(X_train_tfidf, y_train)\r# Đánh giá mô hình\rfrom sklearn.metrics import accuracy_score\ry_pred = model.predict(X_test_tfidf)\raccuracy = accuracy_score(y_test, y_pred)\rprint(f\u0026#34;Accuracy: {accuracy:.4f}\u0026#34;)\r# Lưu model\rimport pickle\rwith open(\u0026#39;sentiment_model.pkl\u0026#39;, \u0026#39;wb\u0026#39;) as f:\rpickle.dump(model, f)\r# Save vectorizer\rwith open(\u0026#39;tfidf_vectorizer.pkl\u0026#39;, \u0026#39;wb\u0026#39;) as f:\rpickle.dump(vectorizer, f) Huấn luyện mô hình\nChạy lệnh python create_sentiment_model.py Bước này sẽ mất thời gian do nó dựa vào sức mạnh CPU của bạn vì scikit-learn không chạy trên GPU. Kết quả: Bạn sẽ thấy độ chính xác sau khi huấn luyện Hai file .pkl được tạo Chúc mừng! Bạn đã xây dựng thành công một mô hình cảm xúc với độ chính xác 90,7%. Bây giờ hãy thử tối ưu hóa nó để có độ chính xác tốt hơn.\n"
},
{
	"uri": "//localhost:1313/vi/6-ecr/6.1-create-ecr/",
	"title": "Tạo ECR",
	"tags": [],
	"description": "",
	"content": " Truy cập AWS Management Console\nTìm kiếm dịch vụ Elastic Container Registry Chọn Elastic Container Registry từ kết quả tìm kiếm Trong Amazon Elastic Container Registry\nTrong Private registry, chọn Repositories Nhấp Create repository Trong General settings\nRepository name: Nhập my-workshop-ecr Nhấp Create Xác nhận\nThành công "
},
{
	"uri": "//localhost:1313/vi/5-elastic-cache/5.1-create-serverless-cache/",
	"title": "Tạo serverless cache",
	"tags": [],
	"description": "",
	"content": " Truy cập AWS Management Console\nTìm kiếm dịch vụ ElastiCache Chọn ElastiCache từ kết quả tìm kiếm Trong Amazon ElastiCache\nChọn Valkey caches ở bên trái Nhấp Create cache Trong Configuration\nEngine: chọn Valkey Deployment option: chọn Serverless Creation method: chọn New cache Trong Settings\nVới Name: nhập my-workshop-cache Engine version: chọn 8 Mở rộng Default settings\nChọn Customize default settings Trong Connectivity\nVPC ID: Chọn my-workshop-vpc Availability Zones: Chọn ap-southeast-1a và ap-southeast-1b Với Security\nChọn Customize your security settings\nTrong Selected security groups, chọn Manage Trong Manage security groups\nChọn valkey-sg Sau đó, nhấp Choose Cuộn xuống, sau đó nhấp Create Đợi Status chuyển thành Available\nSao chép Endpoint và ARN, chúng ta sẽ sử dụng sau này "
},
{
	"uri": "//localhost:1313/vi/4-vpc/4.1-create-vpc/",
	"title": "Tạo VPC",
	"tags": [],
	"description": "",
	"content": " Truy cập AWS Management Console\nTìm kiếm dịch vụ VPC Chọn VPC từ kết quả tìm kiếm Trong VPC Dashboard\nChọn Your VPCs từ menu bên trái Nhấp Create VPC Cấu hình VPC của bạn\nResources: Chọn VPC only Name tag: Nhập my-workshop-vpc IPv4 CIDR: Nhập 10.0.0.0/16 Tenancy: Giữ default Xác nhận tạo VPC\nNhấp Create VPC Kiểm tra sau khi tạo\nThành công "
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.1-dowload-vs-code/",
	"title": "Cài đặt Visual Studio Code",
	"tags": [],
	"description": "",
	"content": "Tổng quan Chọn một IDE hỗ trợ plug-ins cho nhiều ngôn ngữ khác nhau để làm cho việc phát triển trở nên thuận tiện hơn, chẳng hạn như Visual Studio Code, Atom, Notepad++, v.v.\nPlug-ins theo IDE: Tất nhiên, bạn sẽ cần plug-ins cho Markdown (như Markdown All in One, Markdown TOC, v.v.). Khi làm việc với bất kỳ ngôn ngữ nào, VS Code thường sẽ đề xuất các plug-ins liên quan, vì vậy không cần phải lo lắng.\nHướng dẫn Truy cập Visual Studio Code để tải xuống IDE. Truy cập trang Tài liệu để biết thông tin chi tiết và hướng dẫn sử dụng extensions. "
},
{
	"uri": "//localhost:1313/vi/",
	"title": "First Cloud Journey",
	"tags": [],
	"description": "",
	"content": "Hệ thống ML Inference thời gian thực với AWS Lambda \u0026amp; API Gateway Tổng quan Workshop Workshop này cung cấp trải nghiệm thực hành trong việc xây dựng và triển khai hệ thống machine learning inference sẵn sàng cho production sử dụng các công nghệ serverless của AWS. Bạn sẽ học cách tạo một ML API có khả năng mở rộng với thời gian phản hồi dưới 100ms trong khi duy trì hiệu quả chi phí và bảo mật cấp doanh nghiệp.\nNhững gì bạn sẽ xây dựng Một giải pháp ML inference serverless hoàn chỉnh bao gồm:\nPhản hồi API siêu nhanh (\u0026lt; 100ms) sử dụng AWS Lambda và API Gateway Caching thông minh với ElastiCache Valkey để tối ưu hiệu suất Monitoring production sử dụng CloudWatch và AWS X-Ray Bảo mật doanh nghiệp với IAM roles và tích hợp VPC Khả năng auto-scaling xử lý các đợt tăng traffic một cách liền mạch Công nghệ chính AWS Lambda - Serverless compute để hosting ML model API Gateway - Quản lý và định tuyến RESTful API ElastiCache Valkey - Lớp caching hiệu suất cao Python 3.12 - Môi trường runtime với Scikit-learn CloudWatch \u0026amp; X-Ray - Monitoring và tracing toàn diện Mục tiêu học tập Sau khi hoàn thành workshop này, bạn sẽ:\nBiết cách xây dựng một machine learning model Triển khai ML models sẵn sàng cho production trên AWS serverless infrastructure Triển khai các chiến lược caching hiệu quả cho ML workloads Thiết lập hệ thống monitoring và alerting toàn diện Áp dụng các best practices bảo mật AWS cho ứng dụng doanh nghiệp Tối ưu hiệu suất hệ thống cho yêu cầu inference thời gian thực Yêu cầu tiên quyết Làm quen cơ bản với AWS console Hiểu biết về REST APIs và các khái niệm HTTP Kiến thức lập trình Python (mức trung cấp) Tài khoản AWS với quyền phù hợp Nội dung 1. Introduction 2. Preparation 3. Build model 4. VPC 5. ElastiCache 6. ECR 7. Lambda 8. API Gateway 9. Testing 10. Monitoring and Pricing 11. Clean up "
},
{
	"uri": "//localhost:1313/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Tình huống thực tế Hãy tưởng tượng bạn là data scientist tại một công ty thương mại điện tử. Team của bạn đã xây dựng một model phát hiện gian lận cần phân tích mọi giao dịch theo thời gian thực. Yêu cầu kinh doanh rất khắt khe:\nHiệu suất: Phát hiện gian lận trong vòng 50ms để không làm chậm giao dịch Quy mô: Xử lý đợt tăng traffic Black Friday từ 100 lên 10,000 requests mỗi giây Chi phí: Kiểm soát chi phí hạ tầng trong thời gian traffic thấp Độ tin cậy: Yêu cầu 99.9% uptime cho hệ thống production Hệ thống triển khai dựa trên server hiện tại không thể đáp ứng những demands này một cách cost-effective.\nThách thức Triển khai machine learning models lên production phức tạp và tốn kém. Các phương pháp truyền thống gặp khó khăn với:\nĐộ trễ cao - Ứng dụng kinh doanh cần thời gian phản hồi dưới 100ms Scaling không dự đoán được - Đợt tăng traffic khó xử lý hiệu quả Chi phí hạ tầng - Server được cung cấp quá mức lãng phí tiền Gánh nặng vận hành - Quản lý server, scaling và monitoring Giải pháp của chúng tôi: Kiến trúc Serverless ML Kiến trúc serverless AWS giải quyết những vấn đề này bằng cách cung cấp:\nThanh toán theo request - Không có chi phí idle Tự động scaling - Từ không đến hàng nghìn requests Độ trễ dưới 100ms - Với provisioned concurrency Monitoring tích hợp sẵn - Tích hợp CloudWatch và X-Ray Bảo mật doanh nghiệp - Hỗ trợ IAM và VPC Kiến trúc giải pháp Cách hoạt động:\nAPI Gateway nhận và xác thực requests Lambda load model và xử lý inference (với cache check) ElastiCache lưu trữ predictions thường dùng để truy xuất instant CloudWatch monitor hiệu suất và log tất cả activities Kết quả học tập Sau khi hoàn thành workshop này, bạn sẽ:\nBiết cách xây dựng một machine learning model Triển khai ML models có khả năng mở rộng trên AWS serverless infrastructure Triển khai chiến lược caching hiệu quả cho ML workloads Thiết lập production monitoring và alerting Đạt được thời gian phản hồi nhất quán dưới 100ms "
},
{
	"uri": "//localhost:1313/vi/6-ecr/6.2-push-ml-image/",
	"title": "Đẩy ML image lên ECR",
	"tags": [],
	"description": "",
	"content": " Quay lại VS Code Editor\nTạo một folder mới có tên my-workshop-ecr Di chuyển hai file .pkl vào folder này Trong folder my-workshop-ecr\nTạo file lambda_function.py với nội dung như sau: import pickle\rimport json\rimport botocore.session\rfrom botocore.model import ServiceId\rfrom botocore.signers import RequestSigner\rfrom urllib.parse import urlencode, urlunparse, ParseResult\rimport redis\r# ==== Load model và vectorizer (chỉ chạy 1 lần khi cold start) ====\rwith open(\u0026#39;sentiment_model.pkl\u0026#39;, \u0026#39;rb\u0026#39;) as f:\rmodel = pickle.load(f)\rwith open(\u0026#39;tfidf_vectorizer.pkl\u0026#39;, \u0026#39;rb\u0026#39;) as f:\rvectorizer = pickle.load(f)\r# ==== Generate IAM auth token (function) ====\rdef generate_iam_token(username, cache_name, region=\u0026#34;us-east-1\u0026#34;):\rsession = botocore.session.get_session()\rrequest_signer = RequestSigner(\rServiceId(\u0026#34;elasticache\u0026#34;),\rregion,\r\u0026#34;elasticache\u0026#34;,\r\u0026#34;v4\u0026#34;,\rsession.get_credentials(),\rsession.get_component(\u0026#34;event_emitter\u0026#34;),\r)\rquery_params = {\u0026#34;Action\u0026#34;: \u0026#34;connect\u0026#34;, \u0026#34;User\u0026#34;: username, \u0026#34;ResourceType\u0026#34;: \u0026#34;ServerlessCache\u0026#34;}\rurl = urlunparse(\rParseResult(\rscheme=\u0026#34;https\u0026#34;,\rnetloc=cache_name,\rpath=\u0026#34;/\u0026#34;,\rquery=urlencode(query_params),\rparams=\u0026#34;\u0026#34;,\rfragment=\u0026#34;\u0026#34;,\r)\r)\rsigned_url = request_signer.generate_presigned_url(\r{\u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;url\u0026#34;: url, \u0026#34;body\u0026#34;: {}, \u0026#34;headers\u0026#34;: {}, \u0026#34;context\u0026#34;: {}},\roperation_name=\u0026#34;connect\u0026#34;,\rexpires_in=900,\rregion_name=region,\r)\rreturn signed_url.removeprefix(\u0026#34;https://\u0026#34;)\r# ==== Setup Redis client (IAM auth) ====\rusername = \u0026#34;iam-user-01\u0026#34; # Thay bằng IAM user của bạn\rcache_name = \u0026#34;my-workshop-cache\u0026#34; # Thay bằng cache name\relasticache_endpoint = \u0026#34;my-workshop-cache-e8trvn.serverless.apse1.cache.amazonaws.com\u0026#34; # Endpoint cache thực tế\rregion = \u0026#34;ap-southeast-1\u0026#34; #Your cache region\rauth_token = generate_iam_token(username, cache_name, region)\rredis_client = redis.Redis(\rhost=elasticache_endpoint,\rport=6379,\rusername=username,\rpassword=auth_token,\rssl=True,\rssl_cert_reqs=\u0026#34;none\u0026#34;\r)\r# ==== Lambda handler ====\rdef lambda_handler(event, context):\rtry:\r# Parse input\rif \u0026#39;body\u0026#39; in event:\rbody = json.loads(event[\u0026#39;body\u0026#39;])\relse:\rbody = event\rtext = body.get(\u0026#39;text\u0026#39;)\rif not text:\rreturn {\r\u0026#39;statusCode\u0026#39;: 400,\r\u0026#39;body\u0026#39;: json.dumps({\u0026#39;error\u0026#39;: \u0026#39;Missing \u0026#34;text\u0026#34; in request\u0026#39;})\r}\r# Check cache first\rcached_value = redis_client.get(text)\rif cached_value:\rprediction, sentiment = json.loads(cached_value)\relse:\r# Predict if not cached\rX_input = vectorizer.transform([text])\rprediction = model.predict(X_input)[0]\rsentiment = \u0026#34;Positive\u0026#34; if prediction == 1 else \u0026#34;Negative\u0026#34;\r# Save to cache\rredis_client.setex(text, 3600, json.dumps((int(prediction), sentiment)))\r# Return result\rreturn {\r\u0026#39;statusCode\u0026#39;: 200,\r\u0026#39;body\u0026#39;: json.dumps({\r\u0026#39;text\u0026#39;: text,\r\u0026#39;prediction\u0026#39;: int(prediction),\r\u0026#39;sentiment\u0026#39;: sentiment\r})\r}\rexcept Exception as e:\rreturn {\r\u0026#39;statusCode\u0026#39;: 500,\r\u0026#39;body\u0026#39;: json.dumps({\u0026#39;error\u0026#39;: str(e)})\r} Thay thế một số tham số bằng thông tin của riêng bạn Lưu ý: Nhớ xóa số port ở cuối Cache Endpoint Trong folder my-workshop-ecr\nTạo Dockerfile Với nội dung như sau: FROM public.ecr.aws/lambda/python:3.12\r# Copy code\rCOPY lambda_function.py ${LAMBDA_TASK_ROOT}\rCOPY sentiment_model.pkl ${LAMBDA_TASK_ROOT}\rCOPY tfidf_vectorizer.pkl ${LAMBDA_TASK_ROOT}\r# Install requirements\rRUN pip install scikit-learn --target ${LAMBDA_TASK_ROOT}\rRUN pip install redis --target ${LAMBDA_TASK_ROOT}\rRUN pip install botocore --target ${LAMBDA_TASK_ROOT}\rRUN pip install cachetools --target ${LAMBDA_TASK_ROOT}\r# Command to run Lambda\rCMD [\u0026#34;lambda_function.lambda_handler\u0026#34;] Bây giờ chúng ta sẽ sử dụng AWS CLI để xử lý\nNếu bạn chưa có AWS CLI, bạn có thể quay lại chương 2 phần 2.4 để cài đặt. Đảm bảo tài khoản của bạn có Access keys Bạn có thể tạo Access keys bằng các bước sau: Truy cập IAM Service, chọn User, chọn Create access key Trong VS Code Editor\nTrong terminal, gõ: cd my-workshop-ecr Tiếp theo, gõ: aws configure Nhập Access key của bạn Quay lại Elastic Container Registry\nNhấp my-workshop-ecr Nhấp View push command Khởi động docker engine\nSao chép lệnh đầu tiên và gõ vào terminal Sao chép lệnh thứ hai và gõ vào terminal. Đảm bảo bạn đang ở trong thư mục my-workshop-ecr Gõ lệnh thứ ba vào terminal của bạn Gõ lệnh thứ tư vào terminal Sau khi hoàn thành, quay lại AWS ECR bạn sẽ thấy images của mình "
},
{
	"uri": "//localhost:1313/vi/5-elastic-cache/5.2-create-cache-user/",
	"title": "Tạo ElastiCache user",
	"tags": [],
	"description": "",
	"content": " Truy cập AWS Management Console\nTìm kiếm dịch vụ ElastiCache Chọn ElastiCache từ kết quả tìm kiếm Trong Amazon ElastiCache\nChọn User management ở bên trái Nhấp Create user Trong User settings\nVới User ID và User name: Nhập iam-user-01 Engine: Chọn Valkey Trong User authentication settings\nChọn IAM authentication Trong Access string\nNhập: on ~* +@all Sau đó, nhấp Create Sau khi tạo, sao chép giá trị ARN của iam-user-01, chúng ta sẽ sử dụng sau này Trong Amazon ElastiCache\nChọn User group management Nhấp Create user group Trong User group settings\nUser group ID: Nhập iam-user-group-01 Với Selected users, nhấp Manage Chọn iam-user-01, sau đó nhấp Choose Cuộn xuống, nhấp Create Quay lại Valkey cache\nChọn my-workshop-cache Trong my-workshop-cache\nNhấp Modify Cuộn xuống Security\nAccess control: Chọn User group access control list User group: Chọn iam-user-group-01 Cuộn xuống và nhấp Preview changes Nhấp Save changes Xác nhận\nThành công "
},
{
	"uri": "//localhost:1313/vi/4-vpc/4.2-create-private-subnet/",
	"title": "Tạo Private Subnet",
	"tags": [],
	"description": "",
	"content": " Trong VPC dashboard\nChọn Subnets từ menu bên trái Nhấp Create subnet Chọn VPC\nTrong Create subnet Chọn my-workshop-vpc đã tạo trước đó Tạo private subnet đầu tiên\nSubnet name: Nhập Private Subnet 1 Availability Zone: Chọn ap-southeast-1a IPv4 subnet CIDR block: Nhập 10.0.0.0/24 Nhấp Create subnet Xác nhận\nThành công Tạo private subnet thứ hai\nChọn my-workshop-vpc đã tạo trước đó Subnet name: Nhập Private Subnet 2 Availability Zone: Chọn ap-southeast-1b IPv4 subnet CIDR block: Nhập 10.0.1.0/24 Nhấp Create subnet Xác nhận\nThành công "
},
{
	"uri": "//localhost:1313/vi/3-build-model/3.2-optimize--test-model/",
	"title": "Tối ưu và kiểm thử mô hình",
	"tags": [],
	"description": "",
	"content": "Tối ưu hóa Tinh chỉnh/tối ưu hóa tham số cho vectorizer\nTrong file create_sentiment_model.py thêm vào TfidfVectorizer() một số tham số như sau: vectorizer = TfidfVectorizer(\rstop_words=\u0026#39;english\u0026#39;, ngram_range=(1,2),\rmax_features=80000,\rmax_df=0.9, min_df=2 ) Ý nghĩa:\nstop_words=\u0026lsquo;english\u0026rsquo; - Loại bỏ các từ dừng tiếng Anh (the, and, is, in, \u0026hellip;) ngram_range=(1,2) - Sử dụng cả từ đơn (unigrams) và cụm từ 2 từ (bigrams) max_features=80000 - Giới hạn chỉ giữ lại 80,000 đặc trưng quan trọng nhất max_df=0.9 - Loại bỏ từ xuất hiện trong \u0026gt;90% tài liệu (quá phổ biến) min_df=2 - Loại bỏ từ xuất hiện trong \u0026lt;2 tài liệu (quá hiếm) Tối ưu hóa tham số mô hình LogisticRegression\nTrong file create_sentiment_model.py thêm vào LogisticRegression() một số tham số như sau: model = LogisticRegression(\rmax_iter=250,\rC=2.0, solver=\u0026#39;saga\u0026#39;\r) Ý nghĩa:\nmax_iter=250: Số lần lặp tối đa để thuật toán hội tụ (mặc định thường là 100) - Tăng lên để đảm bảo mô hình có đủ thời gian học hết dữ liệu C=2.0: Tham số regularization - Cho phép mô hình \u0026ldquo;học\u0026rdquo; nhiều chi tiết hơn từ dữ liệu solver=\u0026lsquo;saga\u0026rsquo;: Thuật toán tối ưu hóa - Hỗ trợ tốt cho L1, L2 và Elastic Net regularization Huấn luyện lại mô hình để xem độ chính xác mới\nChạy python create_sentiment_model.py Điều này sẽ mất thời gian, hãy đợi! Kết quả: Chúc mừng! Bạn đã tối ưu hóa thành công mô hình từ 90,7% lên 91,3% độ chính xác. Bạn có thể thay đổi giá trị của những tham số trên hoặc thêm một số tham số khác để xem sự khác biệt\nKiểm thử mô hình Tạo file test.py trong cùng thư mục\nSử dụng đoạn code này để kiểm tra mô hình có thể dự đoán một câu là tiêu cực hay tích cực\nimport pickle\r# Load model và vectorizer\rwith open(\u0026#39;sentiment_model.pkl\u0026#39;, \u0026#39;rb\u0026#39;) as f:\rmodel = pickle.load(f)\rwith open(\u0026#39;tfidf_vectorizer.pkl\u0026#39;, \u0026#39;rb\u0026#39;) as f:\rvectorizer = pickle.load(f)\r# Hàm dự đoán sentiment\rdef predict_sentiment(text):\rvec = vectorizer.transform([text])\rpred = model.predict(vec)[0]\rreturn \u0026#34;Positive\u0026#34; if pred == 1 else \u0026#34;Negative\u0026#34;\r# Test\rprint(predict_sentiment(\u0026#34;I love this movie, it was fantastic!\u0026#34;)) Chạy python test.py Hãy thử một câu tiêu cực Vậy là chúng ta đã hoàn thành bước đầu tiên của chủ đề là có một mô hình suy luận. Bây giờ, hãy chuyển sang bước tiếp theo của dự án.\n"
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.2-dowload-postman/",
	"title": "Cài đặt Postman",
	"tags": [],
	"description": "",
	"content": "Tổng quan Postman là công cụ thiết yếu để test và phát triển APIs. Trong workshop ML Inference này, bạn sẽ sử dụng Postman để:\nTest ML API endpoints được triển khai trên AWS API Gateway Gửi inference requests với sample data đến serverless ML model Xác minh response times để đảm bảo yêu cầu độ trễ dưới 100ms Test authentication và cấu hình bảo mật Monitor API behavior dưới các điều kiện load khác nhau Tại sao dùng Postman cho ML APIs? Quick Testing: Gửi POST requests với JSON payloads chứa features để prediction Response Analysis: Xem model predictions và response metadata Performance Monitoring: Kiểm tra response times và debug latency issues Collection Management: Lưu ML inference requests cho các use cases khác nhau Environment Variables: Chuyển đổi giữa development, staging và production endpoints Hướng dẫn Truy cập trang download chính thức của Postman:\n👉 https://www.postman.com/downloads/\nChọn phiên bản phù hợp với hệ điều hành của bạn:\nWindows: .exe installer macOS: .zip hoặc .dmg file Linux: .tar.gz hoặc AppImage Cài đặt và khởi chạy Postman. Bạn có thể đăng nhập hoặc click \u0026ldquo;Skip and take me to the app\u0026rdquo;.\nTính năng chính cho ML API Testing:\nRequest URL: Nhập API Gateway endpoint của bạn Method: Sử dụng POST cho ML inference requests Headers: Set Content-Type: application/json Body: Bao gồm JSON với features cho model prediction Tests: Thêm scripts để validate response format và latency Tạo Collections cho ML Testing:\nML Inference - Fraud Detection Performance Tests Error Handling Tests Cache Validation Tests "
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trước khi bắt đầu Workshop ML Inference này, bạn cần cài đặt và cấu hình các công cụ sau đây. Workshop này tập trung vào việc triển khai các mô hình machine learning dưới dạng serverless containers sử dụng AWS Lambda và API Gateway để thực hiện inference hiệu suất cao.\nCông cụ cần thiết 🛠️ Môi trường phát triển Visual Studio Code - IDE để phát triển code với các extensions cho ML và Docker Python - Ngôn ngữ lập trình cho việc phát triển ML model và tích hợp AWS 🐳 Containerization Docker Desktop - Đóng gói ML models thành containers tối ưu cho AWS Lambda deployment ☁️ Tích hợp AWS AWS CLI - Công cụ dòng lệnh để push Docker images lên Elastic Container Registry (ECR) 🧪 Kiểm thử API Postman - Test ML inference endpoints, verify thời gian phản hồi dưới 100ms, và validate API behavior Quy trình workshop Với các công cụ này, bạn sẽ có thể:\nPhát triển ML models locally sử dụng Python Containerize models với Docker cho Lambda deployment Push container images lên AWS ECR sử dụng AWS CLI Deploy serverless inference APIs trên AWS Lambda Test hiệu suất API và chức năng với Postman Thời gian cài đặt ước tính: 30-45 phút cho việc cài đặt và cấu hình tất cả công cụ\n"
},
{
	"uri": "//localhost:1313/vi/5-elastic-cache/5.3-create-iam-role/",
	"title": "Tạo IAM role",
	"tags": [],
	"description": "",
	"content": " Truy cập AWS Management Console\nTìm kiếm dịch vụ IAM Chọn IAM từ kết quả tìm kiếm Trong Identity and Access Management (IAM)\nChọn Policies Nhấp Create policy Trong Policy editor\nChọn JSON Thay thế cache ARN bằng ARN của riêng bạn {\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Effect\u0026#34; : \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34; : [\r\u0026#34;elasticache:Connect\u0026#34;\r],\r\u0026#34;Resource\u0026#34; : [\r\u0026#34;arn:aws:elasticache:ap-southeast-1:878585013121:serverlesscache:my-workshop-cache\u0026#34;,\r\u0026#34;arn:aws:elasticache:ap-southeast-1:878585013121:user:iam-user-01\u0026#34;\r]\r}\r]\r} Cuộn xuống, nhấp Next Trong Policy Details\nVới Policy name: Nhập elasticache-allow-all Cuộn xuống, nhấp Create policy Xác nhận\nThành công Trong Identity and Access Management (IAM)\nChọn Roles Nhấp Create role Với Trusted entity type\nChọn Custom trust policy {\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Principal\u0026#34;: {\r\u0026#34;Service\u0026#34;: \u0026#34;lambda.amazonaws.com\u0026#34;\r},\r\u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;\r}]\r} Nhấp Next Trong Permissions policies\nFilter by Type Chọn Customer managed Sau đó nhấp Next Trong Role details\nRole name: Nhập elasticache-iam-auth-app Cuộn xuống, nhấp Create role Xác nhận\nThành công "
},
{
	"uri": "//localhost:1313/vi/4-vpc/4.3-create-route-table/",
	"title": "Tạo Route Table",
	"tags": [],
	"description": "",
	"content": "Tạo route table Trong VPC dashboard\nChọn Route tables từ thanh bên trái Nhấp Create route table Trong Route table settings\nName: Route table-Private-1 VPC: Chọn my-workshop-vpc Nhấp Create route table Xác nhận tạo\nThành công Lặp lại bước tương tự cho private route table 2\nName: Route table-Private-2 VPC: Chọn my-workshop-vpc Nhấp Create route table Xác nhận tạo\nThành công Liên kết với subnet Trong Route tables dashboard\nChọn Route table-Private-1 Tiếp theo, chọn tab Subnet associations Trong Explicit subnet associations, nhấp Edit subnet associations Trong Edit subnet associations\nChọn Private Subnet 1 Sau đó, nhấp Save associations Làm tương tự cho Route table-Private-2\nChọn Route table-Private-2 "
},
{
	"uri": "//localhost:1313/vi/3-build-model/",
	"title": "Xây dựng model",
	"tags": [],
	"description": "",
	"content": "Overview Xây dựng một machine learning model thành công cần tuân theo quy trình có hệ thống với các bước chính sau:\nBước 1: Định nghĩa bài toán Xác định loại bài toán (classification, regression, clustering), thiết lập metrics thành công (accuracy, precision, recall), và xác định features cần thiết cho dự đoán.\nBước 2: Thu thập dữ liệu Xây dựng training dataset với labeled data chất lượng cao, đảm bảo sufficient volume, label accuracy, và representative sampling cho problem domain.\nBước 3: Phân tích dữ liệu (EDA) Thực hiện statistical analysis, tìm correlations giữa features và target variables, đánh giá data quality và class balance để hiểu đặc điểm dataset.\nBước 4: Preprocessing và Feature Engineering Data cleaning (xử lý missing values, outliers), feature transformation (normalize, encode), feature selection và creation để chuẩn bị dữ liệu cho algorithms.\nBước 5: Lựa chọn thuật toán Chọn learning algorithms phù hợp dựa trên problem requirements. Cho beginners: Decision Trees, Linear/Logistic Regression, k-NN.\nBước 6: Huấn luyện model Data splitting (80% train, 10% validation, 10% test), model fitting, hyperparameter optimization, và cross-validation để ensure robust performance.\nBước 7: Đánh giá model Measure performance metrics, generalization testing trên test data, error analysis, và statistical significance testing để assess model effectiveness.\nBước 8: Cải thiện và tối ưu Feature engineering refinement, algorithm comparison, ensemble methods, và error pattern analysis để optimize model performance systematically.\n"
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.3-dowload-docker/",
	"title": "Cài đặt Docker Desktop",
	"tags": [],
	"description": "",
	"content": "Tổng quan Docker Desktop là công cụ thiết yếu cho workshop ML Inference này vì AWS Lambda hỗ trợ container-based deployments. Bạn sẽ sử dụng Docker để:\nĐóng gói ML models cùng với dependencies vào containers Test locally trước khi deploy lên AWS Lambda Build optimized images để cold starts nhanh hơn Quản lý Python dependencies và ML libraries hiệu quả Đảm bảo consistent environments giữa development và production Tại sao dùng Containers cho ML Inference? Larger Package Sizes: ML libraries như scikit-learn, numpy vượt quá giới hạn 250MB của Lambda Dependency Management: Complex ML dependencies dễ quản lý hơn trong containers Performance Optimization: Pre-built images giảm cold start times Reproducible Deployments: Cùng environment trên dev, staging, và production Hướng dẫn cài đặt 1. Download Docker Desktop Truy cập trang web chính thức của Docker:\n👉 https://www.docker.com/products/docker-desktop/\nChọn hệ điều hành của bạn:\nWindows: Docker Desktop for Windows (yêu cầu WSL2) macOS: Docker Desktop for Mac (Intel hoặc Apple Silicon) Linux: Docker Desktop for Linux 2. Yêu cầu hệ thống Windows:\nWindows 10/11 64-bit (Pro, Enterprise, Education) WSL2 feature được enabled Tối thiểu 4GB RAM macOS:\nmacOS 10.15 hoặc mới hơn Tối thiểu 4GB RAM Linux:\n64-bit kernel và CPU virtualization support Tối thiểu 4GB RAM 3. Quá trình cài đặt Download installer từ trang web chính thức Chạy installer với administrator privileges Restart máy tính khi được yêu cầu Khởi chạy Docker Desktop và hoàn thành initial setup 4. Xác minh cài đặt Mở terminal/command prompt và chạy:\ndocker --version docker run hello-world Bạn sẽ thấy thông tin version Docker và một test run thành công.\n"
},
{
	"uri": "//localhost:1313/vi/4-vpc/4.4-ceate-security-gr/",
	"title": "Tạo Security Group",
	"tags": [],
	"description": "",
	"content": " Trong VPC dashboard\nChọn Security groups trong thanh bên trái Nhấp Create security group Trong Basic details\nVới Security group name: lambda-sg Với Description: Security Group for Lambda functions accessing ElasticCache (Valkey) inside VPC VPC: Chọn my-workshop-vpc Với Tags Chọn Add new tag Key: Nhập Name Value: Nhập lambda-sg Sau đó, nhấp Create security group Tạo security group thứ hai cho Valkey\nLàm các bước tương tự như trên Với Security group name: valkey-sg Với Description: Allows inbound access from Lambda functions to ElasticCache (Valkey) VPC: Chọn my-workshop-vpc Với Inbound rules: Chọn Add rule Type: Chọn Custom TCP Port range: Nhập 6379 Source: Chọn Custom, chọn lambda-sg Với Tags Chọn Add new tag Key: Nhập Name Value: Nhập valkey-sg Sau đó, nhấp Create security group "
},
{
	"uri": "//localhost:1313/vi/4-vpc/",
	"title": "VPC",
	"tags": [],
	"description": "",
	"content": "Trong workshop này, việc tạo một Virtual Private Cloud (VPC) là bước quan trọng nhằm mô phỏng môi trường mạng riêng trong thực tế khi triển khai hệ thống trên AWS. Thay vì sử dụng VPC mặc định, việc tự thiết lập VPC giúp bạn kiểm soát hoàn toàn cách các dịch vụ như Lambda, ElastiCache giao tiếp với nhau, đồng thời đảm bảo an toàn và bảo mật cao hơn cho tài nguyên. Ngoài ra, nó còn giúp bạn hiểu rõ cách phân chia mạng, thiết lập kết nối nội bộ, và áp dụng các nguyên tắc bảo mật theo chuẩn kiến trúc của AWS.\nCụ thể, việc tạo VPC mang lại các lợi ích sau:\nCách ly mạng: Chia subnet công khai và riêng tư để cô lập tài nguyên quan trọng, tránh truy cập trái phép từ Internet.\nTăng cường bảo mật: Dễ dàng kiểm soát truy cập bằng security group và routing table, tránh lộ tài nguyên như cache hay database.\nThực hành networking thực tế: Học cách kết nối Lambda trong private subnet với dịch vụ nội bộ như ElastiCache mà không cần public IP.\nMô phỏng hệ thống production: Thiết kế gần giống môi trường triển khai thật, phục vụ học tập và ứng dụng thực tiễn.\nChuẩn bị cho các kiến trúc phức tạp hơn: Là nền tảng để mở rộng với các dịch vụ như NAT Gateway, Load Balancer hoặc Service Mesh.\n"
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.4-dowload-aws-cli/",
	"title": "Cài đặt AWS CLI",
	"tags": [],
	"description": "",
	"content": "Tổng quan AWS CLI (Command Line Interface) là công cụ dòng lệnh chính thức để quản lý tài nguyên AWS trực tiếp từ terminal. Trong workshop này, nó sẽ được sử dụng để kết nối đến Elastic Container Registry để push image của model từ docker.\nCài đặt Bước 1: Tải và cài đặt Truy cập trang cài đặt chính thức: 👉 https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html\nDành cho Windows:\nTải file .msi installer và chạy Dành cho macOS:\nbrew install awscli Dành cho Linux (Ubuntu/Debian):\ncurl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install Bước 2: Kiểm tra cài đặt aws --version Kết quả mong đợi: aws-cli/2.x.x Python/3.x.x\nCấu hình Tạo IAM User (Khuyến nghị) Bảo mật: Không sử dụng thông tin tài khoản root AWS. Hãy tạo IAM user thay thế.\nCấu hình CLI aws configure Nhập thông tin xác thực:\nAWS Access Key ID: [Access Key của bạn]\rAWS Secret Access Key: [Secret Key của bạn]\rDefault region name: us-east-1\rDefault output format: "
},
{
	"uri": "//localhost:1313/vi/5-elastic-cache/",
	"title": "ElastiCache",
	"tags": [],
	"description": "",
	"content": "ElastiCache Valkey được sử dụng để cải thiện đáng kể hiệu suất ML inference bằng cách cache kết quả prediction. Không có cache, mỗi ML inference request mất 300-500ms, nhưng với cache chúng ta đạt được 50ms response time (nhanh hơn 90%). Đối với use case phát hiện gian lận yêu cầu response dưới 50ms với 10,000 requests/giây trong peak traffic, cache giảm 70% chi phí Lambda compute đồng thời đảm bảo phản hồi tức thì cho các predictions lặp lại. Hệ thống check cache trước, trả về kết quả cached ngay lập tức nếu tìm thấy, hoặc chạy ML model và cache kết quả cho các requests tương lai, hướng đến 70%+ cache hit rate để đạt hiệu suất tối ưu.\n"
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.5-dowload-python/",
	"title": "Cài đặt Python",
	"tags": [],
	"description": "",
	"content": "Tổng quan Python là ngôn ngữ lập trình cần thiết để phát triển và triển khai các mô hình machine learning. Trong workshop này, Python sẽ được sử dụng để xây dựng ML models, tạo Docker containers, và tích hợp với các dịch vụ AWS.\nTrong workshop này, tác giả sử dụng Python phiên bản 3.12.4.\nCài đặt Bước 1: Tải và cài đặt Python Truy cập trang web chính thức của Python: 👉 https://www.python.org/downloads/\nDành cho Windows:\nTải Python 3.8+ installer (.exe) Tick chọn \u0026ldquo;Add Python to PATH\u0026rdquo; trong quá trình cài đặt Chọn \u0026ldquo;Install for all users\u0026rdquo; Dành cho macOS:\n# Sử dụng Homebrew (khuyến nghị) brew install python # Hoặc tải từ python.org Dành cho Linux (Ubuntu/Debian):\nsudo apt update sudo apt install python3 python3-pip python3-venv Bước 2: Kiểm tra cài đặt python --version # hoặc python3 --version Kết quả mong đợi: Python 3.8.x hoặc cao hơn\npip --version # hoặc pip3 --version "
},
{
	"uri": "//localhost:1313/vi/6-ecr/",
	"title": "ECR",
	"tags": [],
	"description": "",
	"content": "Amazon Elastic Container Registry (ECR) là một dịch vụ Docker container registry được quản lý hoàn toàn, giúp dễ dàng lưu trữ, quản lý và triển khai các Docker container images. Trong workshop này, ECR đóng vai trò là kho lưu trữ trung tâm cho container chứa machine learning model của chúng ta, bao gồm sentiment analysis model cùng tất cả các dependencies. ECR tích hợp liền mạch với AWS Lambda, cho phép chúng ta triển khai các ML model được đóng gói trong container - điều này phù hợp với những model quá lớn hoặc phức tạp so với traditional Lambda deployment packages. Cách tiếp cận này mang lại khả năng quản lý dependencies tốt hơn, thời gian cold start nhanh hơn cho ML workloads, và dễ dàng quản lý phiên bản cho các lần triển khai model.\n"
},
{
	"uri": "//localhost:1313/vi/7-lambda/",
	"title": "Lambda",
	"tags": [],
	"description": "",
	"content": " Truy cập AWS Management Console\nTìm kiếm dịch vụ Lambda Chọn Lambda từ kết quả tìm kiếm Chọn Create a function\nTrong Create function chọn Container image\nFunction name: Nhập demo-ml-inference Container image URI chọn Browser images Amazon ECR image repository chọn my-workshop-ecr Chọn image hiện có Sau đó, nhấp Select image Mở IAM service trong tab khác\nChọn Role ở bên trái Nhấp vào role elasticache-iam-auth-app Chọn Add permissions Chọn Attach policy Tìm kiếm AWSLambdaVPCAccessExecutionRole Chọn AWSLambdaVPCAccessExecutionRole Nhấp Add permissions Quay lại tab Lambda, mở rộng Change default execution role\nChọn Use an existing role Existing role chọn elasticache-iam-auth-app Mở rộng Additional configurations\nVCP tích chọn Enable VPC chọn my-workshop-vpc Subnet chọn Private Subnet 1 và Private Subnet 2 Security group chọn lambda-sg Cuộn xuống, chọn Create function Xác nhận\nThành công Test lambda function\nChọn tab Configuration\nChọn Edit Với Time out thay đổi thành 1 min\nSau đó, chọn Save Chọn tab Test trong function của bạn Với Event JSON, gõ:\n{\r\u0026#34;text\u0026#34;: \u0026#34;I love this movie\u0026#34;\r} Sau đó chọn Test Lambda function chạy thành công Như bạn có thể thấy Duration này là 580.20 ms, đây được gọi là Cold start. Điều này xảy ra khi chúng ta chạy function lần đầu tiên hoặc chạy lại sau một khoảng thời gian dài.\nĐể giảm thiểu vấn đề này, chúng ta sẽ cấu hình Lambda chạy liên tục bằng cách sử dụng Provisioned concurrency\nProvisioned concurrency Chọn tab Configuration\nỞ bên trái, nhấp Concurrency and recursion detection\nNếu Unreserved account concurrency của bạn trông như thế này Điều đó có nghĩa là:\nBạn có các lambda function khác trong tài khoản đang sử dụng concurrency Tài khoản của bạn mới (điều này không phải trường hợp của bạn vì đã 4 tháng tuổi) hoặc tài khoản của bạn không có nhiều usage, và AWS đã đặt giới hạn thấp hơn cho cả hai trường hợp. Đây là các bước ngắn để giải quyết vấn đề này: Nhấp tab Versions\nChọn Publish new version Với Version description nhập v1 Nhấp Publish Sau khi publish version mới, bạn sẽ đã ở trong tab Configuration với Provisioned concurrency Chọn Edit Nhập số lượng Provisioned concurrency mà bạn muốn cho lambda function của mình Nhấp Save Khi bạn sử dụng Provisioned concurrency có nghĩa là function của bạn chạy liên tục và luôn sẵn sàng để sử dụng. Tuy nhiên, càng sử dụng nhiều provisioned concurrency thì càng phải trả nhiều tiền\nĐợi status chuyển thành Ready "
},
{
	"uri": "//localhost:1313/vi/8-api-gateway/",
	"title": "API Gateway",
	"tags": [],
	"description": "",
	"content": " Truy cập AWS Management Console\nTìm kiếm dịch vụ API Gateway Chọn API Gateway từ kết quả tìm kiếm Trong API Gateway dashboard\nNhấp APIs ở bên trái Tiếp theo, chọn Create API ở bên phải Cuộn xuống REST API\nNhấp Build Trong API details\nChọn New API Với API Name nhập my-workshop-api Sau đó, nhấp Create API Sau khi tạo\nNhấp Create resource Trong Resource details\nVới Resource name nhập predict Nhấp Create resource Sau khi tạo\nNhấp Create method Trong Method details\nVới Method type chọn POST\nVới Integration type chọn Lambda function\nVới Lambda function chọn Lambda function của bạn Cuộn xuống và nhấp Create method Sau khi tạo\nNhấp Deploy API Trong Deploy API, với Stage chọn New stage Với Stage name nhập prod Sau đó nhấp Deploy Xác nhận\nThành công Chúng ta sẽ sử dụng Invoke URL để gọi Lambda function của mình\n"
},
{
	"uri": "//localhost:1313/vi/9-testing/",
	"title": "Kiểm thử",
	"tags": [],
	"description": "",
	"content": "Test với Postman Mở Postman Nếu bạn chưa có Postman, bạn có thể quay lại chương 2 phần 2.2 để cài đặt. Tạo workspace của riêng bạn Trong Postman Nhấp +, để tạo request mới Chọn POST Dán Invoke URL vào bên cạnh và thêm /predict vào cuối URL Chọn tab Body (dưới URL) Tiếp theo, chọn raw Sau đó gõ: {\r\u0026#34;text\u0026#34;: \u0026#34;This movie is awsome\u0026#34;\r} Nhấp Send và xem kết quả Test với Locust Quay lại VS Code Editor\nCài đặt thư viện Locust pip install locust Tạo file mới tên locust.py với nội dung như sau: from locust import HttpUser, task, between\rimport json\rimport random\rclass SentimentLoadTest(HttpUser):\rwait_time = between(0, 1) # mỗi user gửi request sau 1-2s\r@task\rdef test_sentiment_api(self):\r# Data mẫu, chỉnh theo input model của bạn\rexample_texts = [\r\u0026#34;I love this product!\u0026#34;,\r\u0026#34;This is terrible, I hate it.\u0026#34;,\r\u0026#34;It\u0026#39;s okay, not too bad but not great.\u0026#34;,\r\u0026#34;Absolutely wonderful experience.\u0026#34;,\r\u0026#34;Worst purchase ever made.\u0026#34;,\r\u0026#34;I\u0026#39;m very happy with my purchase.\u0026#34;,\r\u0026#34;The service was horrible.\u0026#34;,\r\u0026#34;I will definitely buy this again.\u0026#34;,\r\u0026#34;I regret buying this.\u0026#34;,\r\u0026#34;This made my day so much better.\u0026#34;,\r\u0026#34;The quality is disappointing.\u0026#34;,\r\u0026#34;I feel amazing after using this.\u0026#34;,\r\u0026#34;Never buying from here again.\u0026#34;,\r\u0026#34;This is just perfect for my needs.\u0026#34;,\r\u0026#34;It doesn\u0026#39;t work as expected.\u0026#34;,\r\u0026#34;Highly recommend this to everyone.\u0026#34;,\r\u0026#34;Such a waste of money.\u0026#34;,\r\u0026#34;It\u0026#39;s fine, does the job.\u0026#34;,\r\u0026#34;Exceeded my expectations.\u0026#34;,\r\u0026#34;I want a refund immediately.\u0026#34;,\r\u0026#34;Fantastic experience overall.\u0026#34;,\r\u0026#34;Completely useless product.\u0026#34;,\r\u0026#34;Satisfied with what I got.\u0026#34;,\r\u0026#34;Terrible customer service.\u0026#34;,\r\u0026#34;Superb quality and fast delivery.\u0026#34;,\r\u0026#34;Not worth the price at all.\u0026#34;,\r\u0026#34;Works like a charm!\u0026#34;,\r\u0026#34;Disappointed with this purchase.\u0026#34;,\r\u0026#34;Everything was great.\u0026#34;,\r\u0026#34;The item arrived broken.\u0026#34;,\r\u0026#34;Loved it so much!\u0026#34;,\r\u0026#34;Poor packaging and bad quality.\u0026#34;,\r\u0026#34;I am so pleased with this.\u0026#34;,\r\u0026#34;Doesn\u0026#39;t match the description.\u0026#34;,\r\u0026#34;Exactly what I was looking for.\u0026#34;,\r\u0026#34;Extremely dissatisfied.\u0026#34;,\r\u0026#34;Couldn\u0026#39;t be happier.\u0026#34;,\r\u0026#34;I hate it so much.\u0026#34;,\r\u0026#34;This is awesome!\u0026#34;,\r\u0026#34;Worst experience ever.\u0026#34;,\r\u0026#34;Very good product for the price.\u0026#34;,\r\u0026#34;It broke after one use.\u0026#34;,\r\u0026#34;This is my favorite purchase.\u0026#34;,\r\u0026#34;Very low quality material.\u0026#34;,\r\u0026#34;Best thing I\u0026#39;ve bought this year.\u0026#34;,\r\u0026#34;Completely not what I expected.\u0026#34;,\r\u0026#34;I\u0026#39;m extremely happy with it.\u0026#34;,\r\u0026#34;Such an awful experience.\u0026#34;,\r\u0026#34;Five stars from me.\u0026#34;,\r\u0026#34;Would not recommend to anyone.\u0026#34;,\r\u0026#34;It works perfectly.\u0026#34;,\r\u0026#34;Terrible choice I made.\u0026#34;,\r\u0026#34;Beyond my expectations.\u0026#34;,\r\u0026#34;Do not waste your money.\u0026#34;,\r\u0026#34;This is the best!\u0026#34;,\r\u0026#34;I\u0026#39;m so mad about this.\u0026#34;,\r\u0026#34;Loved everything about it.\u0026#34;,\r\u0026#34;I wish I never bought this.\u0026#34;,\r\u0026#34;Absolutely loved it.\u0026#34;,\r\u0026#34;Broke within days.\u0026#34;,\r\u0026#34;I\u0026#39;m very satisfied.\u0026#34;,\r\u0026#34;Worst product on the market.\u0026#34;,\r\u0026#34;Super happy with my purchase.\u0026#34;,\r\u0026#34;I can\u0026#39;t stand this product.\u0026#34;,\r\u0026#34;Will buy again for sure.\u0026#34;,\r\u0026#34;Not as described at all.\u0026#34;,\r\u0026#34;Amazing quality and service.\u0026#34;,\r\u0026#34;Terribly disappointed.\u0026#34;,\r\u0026#34;Very impressed with this.\u0026#34;,\r\u0026#34;Save your money for something better.\u0026#34;,\r\u0026#34;This made me so happy.\u0026#34;,\r\u0026#34;It\u0026#39;s a complete disaster.\u0026#34;,\r\u0026#34;I really like this product.\u0026#34;,\r\u0026#34;I don\u0026#39;t recommend this.\u0026#34;,\r\u0026#34;It feels amazing to use.\u0026#34;,\r\u0026#34;Completely failed my expectations.\u0026#34;,\r\u0026#34;I would buy it again.\u0026#34;,\r\u0026#34;Horrible experience overall.\u0026#34;,\r\u0026#34;Works as advertised.\u0026#34;,\r\u0026#34;Do not buy this.\u0026#34;,\r\u0026#34;It makes me feel great.\u0026#34;,\r\u0026#34;I\u0026#39;m never using this again.\u0026#34;,\r\u0026#34;Best purchase I\u0026#39;ve made recently.\u0026#34;,\r\u0026#34;Worst customer experience ever.\u0026#34;,\r\u0026#34;It does what it says.\u0026#34;,\r\u0026#34;Absolutely not worth it.\u0026#34;,\r\u0026#34;I\u0026#39;m so glad I bought this.\u0026#34;,\r\u0026#34;This is the worst thing ever.\u0026#34;,\r\u0026#34;It\u0026#39;s exactly as shown.\u0026#34;,\r\u0026#34;Disgusting product.\u0026#34;,\r\u0026#34;Very happy with my order.\u0026#34;,\r\u0026#34;I am so disappointed.\u0026#34;,\r\u0026#34;This is fantastic.\u0026#34;,\r\u0026#34;Terrible, just terrible.\u0026#34;,\r\u0026#34;It\u0026#39;s brilliant.\u0026#34;,\r\u0026#34;Does not work at all.\u0026#34;,\r\u0026#34;Such great value for money.\u0026#34;,\r\u0026#34;Awful quality.\u0026#34;,\r\u0026#34;Perfect in every way.\u0026#34;,\r\u0026#34;Completely unusable.\u0026#34;\r]\rinput_text = random.choice(example_texts)\rpayload = {\r\u0026#34;text\u0026#34;: input_text # thay đổi key này nếu API của bạn cần key khác\r}\rheaders = {\r\u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;\r}\rwith self.client.post(\u0026#34;/predict\u0026#34;, data=json.dumps(payload), headers=headers, catch_response=True) as response:\rif response.status_code == 200:\rresponse.success()\relse:\rresponse.failure(f\u0026#34;Failed with status code {response.status_code}, body: {response.text}\u0026#34;) Chạy locust -f locust.py --host \u0026lt;Your Invoke URL\u0026gt; Mở trình duyệt và truy cập http://localhost:8089/ Với number of user nhập số lượng bạn muốn Với Ramp up nhập 1 Nhấp START Đợi một phút sau đó nhấp STOP Kết quả: Hầu hết đáp ứng yêu cầu (\u0026lt;100ms). Tuy nhiên, với 99%ile là 130ms nên không đáp ứng yêu cầu (\u0026lt;100ms) Nhấp tab CHARTS để xem chi tiết "
},
{
	"uri": "//localhost:1313/vi/10-monitoring/",
	"title": "Giám sát và chi phí",
	"tags": [],
	"description": "",
	"content": "Giám sát Trong dashboard Lambda function của bạn\nNhấp tab Configuration Chọn Monitoring and operations tools trong thanh bên trái Trong Additional monitoring tools chọn Edit Kích hoạt X-Ray Nhấp Save Xác nhận\nX-Ray đã được bật Truy cập dịch vụ CloudWatch (Gọi lại lambda function của bạn)\nChọn trace Chọn Trace mà bạn muốn xem chi tiết Phân tích chi phí Tính toán chi phí hàng tháng\nCấu hình dịch vụ:\nECR: 1 image (358.18MB) ElastiCache Serverless: Valkey engine Lambda: 50 Provisioned Concurrency units CloudWatch: Log monitoring X-Ray: Distributed tracing API Gateway: REST API only Chi tiết phân tích chi phí hàng tháng\nECR (Elastic Container Registry)\nStorage: 358.18MB = 0.358GB\rPricing: $0.10 per GB per month\rMonthly Cost: 0.358 × $0.10 = $0.036 ElastiCache Serverless (Valkey)\nDựa trên usage pattern: ~2.9 GB-Hours hàng ngày\rƯớc tính hàng tháng: 2.9 × 30 = 87 GB-Hours\rPricing: $0.101 per GB-Hour for data storage\rMonthly Cost: 87 × $0.101 = $8.79 Lambda với Provisioned Concurrency ⚠️ CHI PHÍ CHÍNH\nConfiguration: 50 concurrent executions\rMemory allocation: 1GB (thông thường cho ML workloads)\rMonthly compute time: 50 × 1GB × 30 days × 24 hours × 3600 seconds\r= 129,600,000 GB-seconds per month\rPricing: $0.0000041667 per GB-second\rMonthly Cost: 129,600,000 × $0.0000041667 = $540.00 API Gateway (REST API)\nƯớc tính monthly requests: ~30,000 (scale từ workshop usage)\rFree Tier: 1 triệu requests đầu tiên mỗi tháng\rMonthly Cost: $0.00 (trong free tier) CloudWatch + X-Ray\nCloudWatch Logs: Basic monitoring trong free tier\rX-Ray Traces: Ước tính 200 traces/tháng (trong 100K free tier)\rMonthly Cost: $0.00 (trong free tier) Tổng hợp chi phí hàng tháng\nDịch vụ Chi phí hàng tháng Tỷ lệ phần trăm Lambda (Provisioned Concurrency) $540.00 98.4% ElastiCache Serverless $8.79 1.6% ECR Storage $0.036 0.007% API Gateway $0.00 0% CloudWatch/X-Ray $0.00 0% TỔNG CỘNG $548.83 100% Chiến lược tối ưu hóa chi phí\nKhuyến nghị quan trọng: Cấu hình hiện tại với 50 Provisioned Concurrency cực kỳ đắt đỏ cho production.\nCác cấu hình thay thế:\nLựa chọn 1: Giảm Provisioned Concurrency\n5 Provisioned Concurrency units thay vì 50\rMonthly Cost: $54.00 (tiết kiệm 90%)\rTotal Monthly: $62.83 Lựa chọn 2: Chỉ giờ hành chính (8AM-8PM)\n50 units × 12 giờ/ngày thay vì 24/7\rMonthly Cost: $270.00 (tiết kiệm 50%)\rTotal Monthly: $278.83 Lựa chọn 3: Không có Provisioned Concurrency\nSử dụng Lambda thông thường với cold starts\rMonthly Cost: ~$2-5 cho compute + requests\rTotal Monthly: $10.83 (tiết kiệm 98%) Khuyến nghị cho Production\nCho Development/Testing:\nSử dụng Lựa chọn 3 (Không có Provisioned Concurrency): $10.83/tháng Cho Production (Low Traffic):\nSử dụng Lựa chọn 1 (5 Provisioned Concurrency): $62.83/tháng Cho Production (High Performance):\nSử dụng Lựa chọn 2 (Chỉ giờ hành chính): $278.83/tháng Cảnh báo chi phí quan trọng: Cấu hình hiện tại của bạn có chi phí $548.83/tháng - điều này chủ yếu do 50 Provisioned Concurrency units chạy 24/7. Hãy xem xét giảm xuống 5-10 units hoặc thực hiện lập lịch theo thời gian để tiết kiệm đáng kể.\nTác động tối ưu hóa chi phí:\nCấu hình hiện tại: $548.83/tháng Tối ưu hóa cho testing: $10.83/tháng (tiết kiệm 98%) Tối ưu hóa cho production: $62.83/tháng (tiết kiệm 89%) "
},
{
	"uri": "//localhost:1313/vi/11-clean-up/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Xóa Lambda function Trong Lambda function dashboard Chọn demo-ml-inference Nhấp Action chọn Delete Gõ confirm Nhấp Delete Xóa ElastiCache Trong ElastiCache dashboard Chọn Cache của bạn Nhấp Action chọn Delete Với Create backup chọn No Gõ tên cache của bạn Nhấp Delete Trong User management xóa iam-user-01 Nhấp Delete Trong User group management xóa iam-user-group-01 Xóa Elastic Container Registry Trong Elastic Container Registry dashboard Chọn repository của bạn Nhấp Delete Xóa API Gateway Trong API Gateway dashboard Chọn api của bạn Nhấp Delete Xóa Policy và Role Trong Policies dashboard Xóa elasticache-allow-all và AWSLambdaTracerAccessExecutionRole-... Trong Role dashboard xóa elasticache-iam-auth-app "
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]